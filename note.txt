7000:
training_args = Seq2SeqTrainingArguments(
    output_dir=model_name,       # output directory
    eval_strategy="epoch",                # evaluation strategy
    learning_rate=5e-5,                   # increased learning rate
    per_device_train_batch_size=8,        # increased batch size for training
    per_device_eval_batch_size=8,         # increased batch size for evaluation
    num_train_epochs=5,                   # reduced number of epochs
    weight_decay=0.01,                    # weight decay for regularization
    logging_dir="./logs",                 # directory for logs
    logging_steps=500,                    # log every 500 steps
    predict_with_generate=True,           # enables generate for predictions
    save_strategy="epoch",                # save model every epoch
)

300-v1:
training_args = Seq2SeqTrainingArguments(
    output_dir=model_name,       # output directory
    eval_strategy="epoch",                # evaluation strategy
    learning_rate=5e-5,                   # increased learning rate
    per_device_train_batch_size=4,        # increased batch size for training
    per_device_eval_batch_size=8,         # increased batch size for evaluation
    num_train_epochs=5,                   # reduced number of epochs
    weight_decay=0.01,                    # weight decay for regularization
    logging_dir="./logs",                 # directory for logs
    logging_steps=500,                    # log every 500 steps
    predict_with_generate=True,           # enables generate for predictions
    save_strategy="epoch",                # save model every epoch
)
{'eval_loss': 0.35260170698165894, 'eval_runtime': 8.5726, 'eval_samples_per_second': 11.548, 'eval_steps_per_second': 1.516, 'epoch': 1.0}
{'eval_loss': 0.3724861145019531, 'eval_runtime': 7.1514, 'eval_samples_per_second': 13.843, 'eval_steps_per_second': 1.818, 'epoch': 2.0}
{'eval_loss': 0.40207865834236145, 'eval_runtime': 7.1334, 'eval_samples_per_second': 13.878, 'eval_steps_per_second': 1.822, 'epoch': 3.0}
{'eval_loss': 0.43235206604003906, 'eval_runtime': 7.135, 'eval_samples_per_second': 13.875, 'eval_steps_per_second': 1.822, 'epoch': 4.0}
{'eval_loss': 0.44135791063308716, 'eval_runtime': 7.5193, 'eval_samples_per_second': 13.166, 'eval_steps_per_second': 1.729, 'epoch': 5.0}
{'train_runtime': 584.6291, 'train_samples_per_second': 2.566, 'train_steps_per_second': 0.641, 'train_loss': 0.31695817057291664, 'epoch': 5.0}
Evaluation results:
{'eval_loss': 0.44135791063308716, 'eval_runtime': 7.1956, 'eval_samples_per_second': 13.758, 'eval_steps_per_second': 1.807, 'epoch': 5.0}

300-v2:
training_args = Seq2SeqTrainingArguments(
    output_dir=model_name,       # output directory
    eval_strategy="epoch",                # evaluation strategy
    learning_rate=5e-5,                   # increased learning rate
    per_device_train_batch_size=4,        # increased batch size for training
    per_device_eval_batch_size=8,         # increased batch size for evaluation
    num_train_epochs=10,                   # reduced number of epochs
    weight_decay=0.01,                    # weight decay for regularization
    logging_dir="./logs",                 # directory for logs
    logging_steps=500,                    # log every 500 steps
    predict_with_generate=True,           # enables generate for predictions
    save_strategy="epoch",                # save model every epoch
)
{'eval_loss': 0.35712406039237976, 'eval_runtime': 7.4433, 'eval_samples_per_second': 13.301, 'eval_steps_per_second': 1.747, 'epoch': 1.0}
{'eval_loss': 0.37940284609794617, 'eval_runtime': 7.1099, 'eval_samples_per_second': 13.924, 'eval_steps_per_second': 1.828, 'epoch': 2.0}
{'eval_loss': 0.40835583209991455, 'eval_runtime': 7.112, 'eval_samples_per_second': 13.92, 'eval_steps_per_second': 1.828, 'epoch': 3.0}
{'eval_loss': 0.44312939047813416, 'eval_runtime': 7.1133, 'eval_samples_per_second': 13.918, 'eval_steps_per_second': 1.828, 'epoch': 4.0}
{'eval_loss': 0.4593619704246521, 'eval_runtime': 7.1177, 'eval_samples_per_second': 13.909, 'eval_steps_per_second': 1.826, 'epoch': 5.0}
{'eval_loss': 0.4862178564071655, 'eval_runtime': 7.1561, 'eval_samples_per_second': 13.834, 'eval_steps_per_second': 1.817, 'epoch': 6.0}
{'loss': 0.2445, 'grad_norm': 0.40245601534843445, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}
{'eval_loss': 0.4870406687259674, 'eval_runtime': 7.1162, 'eval_samples_per_second': 13.912, 'eval_steps_per_second': 1.827, 'epoch': 7.0}
{'eval_loss': 0.4967643618583679, 'eval_runtime': 7.1055, 'eval_samples_per_second': 13.933, 'eval_steps_per_second': 1.83, 'epoch': 8.0}
{'eval_loss': 0.5001032948493958, 'eval_runtime': 7.1072, 'eval_samples_per_second': 13.93, 'eval_steps_per_second': 1.829, 'epoch': 9.0}
{'eval_loss': 0.5018297433853149, 'eval_runtime': 7.4888, 'eval_samples_per_second': 13.22, 'eval_steps_per_second': 1.736, 'epoch': 10.0}
{'train_runtime': 2038.8311, 'train_samples_per_second': 1.471, 'train_steps_per_second': 0.368, 'train_loss': 0.1675028591156006, 'epoch': 10.0}
Evaluation results:
{'eval_loss': 0.5018297433853149, 'eval_runtime': 7.159, 'eval_samples_per_second': 13.829, 'eval_steps_per_second': 1.816, 'epoch': 10.0}

300-v3:
training_args = Seq2SeqTrainingArguments(
    output_dir=model_name,       # output directory
    eval_strategy="epoch",                # evaluation strategy
    learning_rate=3e-5,                   # increased learning rate
    per_device_train_batch_size=4,        # increased batch size for training
    per_device_eval_batch_size=8,         # increased batch size for evaluation
    num_train_epochs=10,                   # reduced number of epochs
    weight_decay=0.01,                    # weight decay for regularization
    logging_dir="./logs",                 # directory for logs
    logging_steps=500,                    # log every 500 steps
    predict_with_generate=True,           # enables generate for predictions
    save_strategy="epoch",                # save model every epoch
)
{'eval_loss': 0.35160204768180847, 'eval_runtime': 7.4724, 'eval_samples_per_second': 13.249, 'eval_steps_per_second': 1.74, 'epoch': 1.0}
{'eval_loss': 0.36308950185775757, 'eval_runtime': 7.1578, 'eval_samples_per_second': 13.831, 'eval_steps_per_second': 1.816, 'epoch': 2.0}
{'eval_loss': 0.38599762320518494, 'eval_runtime': 7.155, 'eval_samples_per_second': 13.836, 'eval_steps_per_second': 1.817, 'epoch': 3.0}
{'eval_loss': 0.42061132192611694, 'eval_runtime': 7.1605, 'eval_samples_per_second': 13.826, 'eval_steps_per_second': 1.816, 'epoch': 4.0}
{'eval_loss': 0.4458845257759094, 'eval_runtime': 7.1825, 'eval_samples_per_second': 13.784, 'eval_steps_per_second': 1.81, 'epoch': 5.0}
{'eval_loss': 0.46442359685897827, 'eval_runtime': 7.1569, 'eval_samples_per_second': 13.833, 'eval_steps_per_second': 1.816, 'epoch': 6.0}
{'loss': 0.3029, 'grad_norm': 0.9133740663528442, 'learning_rate': 9.999999999999999e-06, 'epoch': 6.67}
{'eval_loss': 0.4727107584476471, 'eval_runtime': 7.1596, 'eval_samples_per_second': 13.828, 'eval_steps_per_second': 1.816, 'epoch': 7.0}
{'eval_loss': 0.4793180823326111, 'eval_runtime': 7.1583, 'eval_samples_per_second': 13.83, 'eval_steps_per_second': 1.816, 'epoch': 8.0}
{'eval_loss': 0.48457592725753784, 'eval_runtime': 7.1517, 'eval_samples_per_second': 13.843, 'eval_steps_per_second': 1.818, 'epoch': 9.0}
{'eval_loss': 0.48685991764068604, 'eval_runtime': 7.2598, 'eval_samples_per_second': 13.637, 'eval_steps_per_second': 1.791, 'epoch': 10.0}
{'train_runtime': 1067.2915, 'train_samples_per_second': 2.811, 'train_steps_per_second': 0.703, 'train_loss': 0.20717770608266195, 'epoch': 10.0}
Evaluation results:
{'eval_loss': 0.48685991764068604, 'eval_runtime': 7.2458, 'eval_samples_per_second': 13.663, 'eval_steps_per_second': 1.794, 'epoch': 10.0}

300-v4:
training_args = Seq2SeqTrainingArguments(
    output_dir=model_name,       # output directory
    eval_strategy="epoch",                # evaluation strategy
    learning_rate=3e-5,                   # increased learning rate
    per_device_train_batch_size=4,        # increased batch size for training
    per_device_eval_batch_size=8,         # increased batch size for evaluation
    num_train_epochs=40,                   # reduced number of epochs
    weight_decay=0.01,                    # weight decay for regularization
    logging_dir="./logs",                 # directory for logs
    logging_steps=500,                    # log every 500 steps
    predict_with_generate=True,           # enables generate for predictions
    save_strategy="epoch",                # save model every epoch
)
{'eval_loss': 0.35352203249931335, 'eval_runtime': 7.5881, 'eval_samples_per_second': 13.047, 'eval_steps_per_second': 1.713, 'epoch': 1.0}
{'eval_loss': 0.3638303577899933, 'eval_runtime': 7.114, 'eval_samples_per_second': 13.916, 'eval_steps_per_second': 1.827, 'epoch': 2.0}
{'eval_loss': 0.3925599753856659, 'eval_runtime': 7.107, 'eval_samples_per_second': 13.93, 'eval_steps_per_second': 1.829, 'epoch': 3.0}
{'eval_loss': 0.42396557331085205, 'eval_runtime': 7.1193, 'eval_samples_per_second': 13.906, 'eval_steps_per_second': 1.826, 'epoch': 4.0}
{'eval_loss': 0.4503929316997528, 'eval_runtime': 7.1105, 'eval_samples_per_second': 13.923, 'eval_steps_per_second': 1.828, 'epoch': 5.0}
{'eval_loss': 0.4777279496192932, 'eval_runtime': 7.1229, 'eval_samples_per_second': 13.899, 'eval_steps_per_second': 1.825, 'epoch': 6.0}
{'loss': 0.3036, 'grad_norm': 0.6829103827476501, 'learning_rate': 2.5e-05, 'epoch': 6.67}
{'eval_loss': 0.48065078258514404, 'eval_runtime': 7.1286, 'eval_samples_per_second': 13.888, 'eval_steps_per_second': 1.824, 'epoch': 7.0}
{'eval_loss': 0.48923009634017944, 'eval_runtime': 7.1119, 'eval_samples_per_second': 13.92, 'eval_steps_per_second': 1.828, 'epoch': 8.0}
{'eval_loss': 0.4987020194530487, 'eval_runtime': 7.1397, 'eval_samples_per_second': 13.866, 'eval_steps_per_second': 1.821, 'epoch': 9.0}
{'eval_loss': 0.5024929642677307, 'eval_runtime': 7.1072, 'eval_samples_per_second': 13.929, 'eval_steps_per_second': 1.829, 'epoch': 10.0}
{'eval_loss': 0.5050768256187439, 'eval_runtime': 7.1293, 'eval_samples_per_second': 13.886, 'eval_steps_per_second': 1.823, 'epoch': 11.0}
{'eval_loss': 0.5188449025154114, 'eval_runtime': 7.127, 'eval_samples_per_second': 13.891, 'eval_steps_per_second': 1.824, 'epoch': 12.0}
{'eval_loss': 0.5275213718414307, 'eval_runtime': 7.1394, 'eval_samples_per_second': 13.867, 'eval_steps_per_second': 1.821, 'epoch': 13.0}
{'loss': 0.0163, 'grad_norm': 0.3624323010444641, 'learning_rate': 1.9999999999999998e-05, 'epoch': 13.33}
{'eval_loss': 0.5272607803344727, 'eval_runtime': 7.1878, 'eval_samples_per_second': 13.773, 'eval_steps_per_second': 1.809, 'epoch': 14.0}
{'eval_loss': 0.5245524048805237, 'eval_runtime': 7.1101, 'eval_samples_per_second': 13.924, 'eval_steps_per_second': 1.828, 'epoch': 15.0}
{'eval_loss': 0.5343958139419556, 'eval_runtime': 7.1407, 'eval_samples_per_second': 13.864, 'eval_steps_per_second': 1.821, 'epoch': 16.0}
{'eval_loss': 0.5268176794052124, 'eval_runtime': 7.1246, 'eval_samples_per_second': 13.895, 'eval_steps_per_second': 1.825, 'epoch': 17.0}
{'eval_loss': 0.5383400321006775, 'eval_runtime': 7.1497, 'eval_samples_per_second': 13.847, 'eval_steps_per_second': 1.818, 'epoch': 18.0}
{'eval_loss': 0.534984827041626, 'eval_runtime': 7.1138, 'eval_samples_per_second': 13.917, 'eval_steps_per_second': 1.827, 'epoch': 19.0}
{'loss': 0.0127, 'grad_norm': 0.535477340221405, 'learning_rate': 1.5e-05, 'epoch': 20.0}
{'eval_loss': 0.5449403524398804, 'eval_runtime': 7.1186, 'eval_samples_per_second': 13.907, 'eval_steps_per_second': 1.826, 'epoch': 20.0}
{'eval_loss': 0.5455090403556824, 'eval_runtime': 7.1483, 'eval_samples_per_second': 13.849, 'eval_steps_per_second': 1.819, 'epoch': 21.0}
{'eval_loss': 0.5493350625038147, 'eval_runtime': 7.1609, 'eval_samples_per_second': 13.825, 'eval_steps_per_second': 1.815, 'epoch': 22.0}
{'eval_loss': 0.5500041246414185, 'eval_runtime': 7.1032, 'eval_samples_per_second': 13.937, 'eval_steps_per_second': 1.83, 'epoch': 23.0}
{'eval_loss': 0.5531063079833984, 'eval_runtime': 7.1289, 'eval_samples_per_second': 13.887, 'eval_steps_per_second': 1.824, 'epoch': 24.0}
{'eval_loss': 0.5493234395980835, 'eval_runtime': 7.1406, 'eval_samples_per_second': 13.864, 'eval_steps_per_second': 1.821, 'epoch': 25.0}
{'eval_loss': 0.5522439479827881, 'eval_runtime': 7.1155, 'eval_samples_per_second': 13.913, 'eval_steps_per_second': 1.827, 'epoch': 26.0}
{'loss': 0.0105, 'grad_norm': 0.25778117775917053, 'learning_rate': 9.999999999999999e-06, 'epoch': 26.67}
{'eval_loss': 0.5516325831413269, 'eval_runtime': 7.1186, 'eval_samples_per_second': 13.907, 'eval_steps_per_second': 1.826, 'epoch': 27.0}
{'eval_loss': 0.5521422624588013, 'eval_runtime': 7.1124, 'eval_samples_per_second': 13.919, 'eval_steps_per_second': 1.828, 'epoch': 28.0}
{'eval_loss': 0.555120587348938, 'eval_runtime': 7.1203, 'eval_samples_per_second': 13.904, 'eval_steps_per_second': 1.826, 'epoch': 29.0}
{'eval_loss': 0.5552337765693665, 'eval_runtime': 7.1167, 'eval_samples_per_second': 13.911, 'eval_steps_per_second': 1.827, 'epoch': 30.0}
{'eval_loss': 0.558979332447052, 'eval_runtime': 7.1942, 'eval_samples_per_second': 13.761, 'eval_steps_per_second': 1.807, 'epoch': 31.0}
{'eval_loss': 0.5603408217430115, 'eval_runtime': 7.1129, 'eval_samples_per_second': 13.918, 'eval_steps_per_second': 1.828, 'epoch': 32.0}
{'eval_loss': 0.5636863112449646, 'eval_runtime': 7.3929, 'eval_samples_per_second': 13.391, 'eval_steps_per_second': 1.758, 'epoch': 33.0}
{'loss': 0.0097, 'grad_norm': 0.18316490948200226, 'learning_rate': 4.9999999999999996e-06, 'epoch': 33.33}
{'eval_loss': 0.5611738562583923, 'eval_runtime': 7.1214, 'eval_samples_per_second': 13.902, 'eval_steps_per_second': 1.825, 'epoch': 34.0}
{'eval_loss': 0.5624171495437622, 'eval_runtime': 7.1491, 'eval_samples_per_second': 13.848, 'eval_steps_per_second': 1.818, 'epoch': 35.0}
{'eval_loss': 0.564393162727356, 'eval_runtime': 7.1247, 'eval_samples_per_second': 13.895, 'eval_steps_per_second': 1.825, 'epoch': 36.0}
{'eval_loss': 0.5634423494338989, 'eval_runtime': 7.1423, 'eval_samples_per_second': 13.861, 'eval_steps_per_second': 1.82, 'epoch': 37.0}
{'eval_loss': 0.5647045969963074, 'eval_runtime': 7.1229, 'eval_samples_per_second': 13.899, 'eval_steps_per_second': 1.825, 'epoch': 38.0}
{'eval_loss': 0.5644857883453369, 'eval_runtime': 7.1266, 'eval_samples_per_second': 13.892, 'eval_steps_per_second': 1.824, 'epoch': 39.0}
{'loss': 0.0093, 'grad_norm': 0.2599503993988037, 'learning_rate': 0.0, 'epoch': 40.0}
{'eval_loss': 0.5649091005325317, 'eval_runtime': 7.5026, 'eval_samples_per_second': 13.195, 'eval_steps_per_second': 1.733, 'epoch': 40.0}
{'train_runtime': 4500.5369, 'train_samples_per_second': 2.666, 'train_steps_per_second': 0.667, 'train_loss': 0.06035443671544393, 'epoch': 40.0}
Evaluation results:
{'eval_loss': 0.5649091005325317, 'eval_runtime': 7.1938, 'eval_samples_per_second': 13.762, 'eval_steps_per_second': 1.807, 'epoch': 40.0}